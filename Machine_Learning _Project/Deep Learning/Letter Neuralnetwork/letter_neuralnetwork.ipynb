{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import neurolab as nl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      letter  xbox  ybox  width  height  onpix  xbar  ybar  x2bar  y2bar  \\\n",
      "0          T     2     8      3       5      1     8    13      0      6   \n",
      "1          I     5    12      3       7      2    10     5      5      4   \n",
      "2          D     4    11      6       8      6    10     6      2      6   \n",
      "3          N     7    11      6       6      3     5     9      4      6   \n",
      "4          G     2     1      3       1      1     8     6      6      6   \n",
      "...      ...   ...   ...    ...     ...    ...   ...   ...    ...    ...   \n",
      "19995      D     2     2      3       3      2     7     7      7      6   \n",
      "19996      C     7    10      8       8      4     4     8      6      9   \n",
      "19997      T     6     9      6       7      5     6    11      3      7   \n",
      "19998      S     2     3      4       2      1     8     7      2      6   \n",
      "19999      A     4     9      6       6      2     9     5      3      1   \n",
      "\n",
      "       xybar  x2ybar  xy2bar  xedge  xedgey  yedge  yedgex  \n",
      "0          6      10       8      0       8      0       8  \n",
      "1         13       3       9      2       8      4      10  \n",
      "2         10       3       7      3       7      3       9  \n",
      "3          4       4      10      6      10      2       8  \n",
      "4          6       5       9      1       7      5      10  \n",
      "...      ...     ...     ...    ...     ...    ...     ...  \n",
      "19995      6       6       4      2       8      3       7  \n",
      "19996     12       9      13      2       9      3       7  \n",
      "19997     11       9       5      2      12      2       4  \n",
      "19998     10       6       8      1       9      5       8  \n",
      "19999      8       1       8      2       7      2       8  \n",
      "\n",
      "[20000 rows x 17 columns]\n"
     ]
    }
   ],
   "source": [
    "# data= pd.read_csv(r'C:\\Users\\bichl\\Documents\\Machine_Learning _Project\\Deep Learning\\letterdata.csv')\n",
    "\n",
    "data= pd.read_csv(r'/Users/lientran/Documents/Machine_Learning _Project/Deep Learning/letterdata.csv')\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input and output variables\n",
    "inputs = data[['xbox', 'ybox', 'width','height', 'onpix', 'xbar', 'ybar', 'x2bar','y2bar']].values\n",
    "targets = data['letter'].values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network architecture, Each tuple represents the minimum and maximum values for the inputs in a specific layer. In this case, there are four layers with different input ranges.\n",
    "\n",
    "#[5, 1]: This is a list that defines the number of neurons in each layer. In this network, there are two layers: the first layer with 5 neurons and the second layer with 1 neuron.\n",
    "\n",
    "nn = nl.net.newff([(18, 44), (0, 8), (0, 2), (0, 2)], [5, 1], [nl.trans.LogSig(), nl.trans.LogSig()])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs shape: (20000, 9)\n",
      "nn shape: 4\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/lientran/Documents/Machine_Learning _Project/Deep Learning/letter_neuralnetwork.ipynb Cell 5\u001b[0m line \u001b[0;36m9\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#W4sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mnn shape:\u001b[39m\u001b[39m'\u001b[39m, nn\u001b[39m.\u001b[39mci)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#W4sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m#  Training the neural network nn using gradient descent from neurolab. The network will be trained on the entire dataset 500 times. The training progress will be shown every 100 epochs.The training will stop once the error falls below 0.01, or it reaches 500 epochs (whichever happens first).\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#W4sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m error \u001b[39m=\u001b[39m nl\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mtrain_gd(nn, inputs, targets, epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, show\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, goal\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m)\n",
      "File \u001b[0;32m~/Documents/Machine_Learning _Project/.venv/lib/python3.11/site-packages/neurolab/core.py:322\u001b[0m, in \u001b[0;36mTrainer.__call__\u001b[0;34m(self, net, input, target, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masfarray(\u001b[39minput\u001b[39m)\n\u001b[1;32m    321\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m--> 322\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m net\u001b[39m.\u001b[39mci\n\u001b[1;32m    323\u001b[0m args\u001b[39m.\u001b[39mappend(\u001b[39minput\u001b[39m)\n\u001b[1;32m    324\u001b[0m \u001b[39mif\u001b[39;00m target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Checking the dimensions of your data and the neural network's structure to ensure they match correctly.\n",
    "\n",
    "\n",
    "print('inputs shape:', inputs.shape)\n",
    "print('nn shape:', nn.ci)\n",
    "\n",
    "\n",
    "#  Training the neural network nn using gradient descent from neurolab. The network will be trained on the entire dataset 500 times. The training progress will be shown every 100 epochs.The training will stop once the error falls below 0.01, or it reaches 500 epochs (whichever happens first).\n",
    "error = nl.train.train_gd(nn, inputs, targets, epochs=500, show=100, goal=0.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Running the garson function with the trained neural network (net) to get a matrix of feature importances, where each row corresponds to an input feature, and each column corresponds to a hidden neuron. This can be useful for understanding which input features have the most influence on the network's output. Define the function of Garson's Algorithm.\n",
    "def garson(net):\n",
    "    \"\"\"\n",
    "    Calculate Garson's algorithm to evaluate feature importance.\n",
    "    \"\"\"\n",
    "    inputs = np.hstack(net.layers[0].np['w'])  # Extracts the weights (or connections) between the input layer and the hidden layer of the neural network. The weights are flattened into a 1D array using np.hstack, and they are stored in the inputs variable. These weights represent the importance of each input feature for the hidden layer.\n",
    "    hidden = np.hstack(net.layers[1].np['w'])  # Extracts the weights between the hidden layer and the output layer of the neural network and stores them in the hidden variable. These weights represent the importance of the hidden neurons for the output.\n",
    "    total = np.abs(hidden).sum(axis=0)  # Calculates the absolute sum of weights for each neuron in the hidden layer. It represents the total importance of each hidden neuron for the output layer.\n",
    "    importance = np.zeros(inputs.shape)  # Initializes a matrix of zeros with the same shape as the inputs matrix. This matrix will store the calculated importance of each input feature for the output.\n",
    "    \n",
    "    # The subsequent loop goes through each input feature and calculates its importance by multiplying the absolute value of the input's weights by the corresponding hidden weights and dividing by the total importance of the hidden neuron. This is the core of Garson's algorithm, which quantifies the contribution of each input feature to the output.\n",
    "    \n",
    "    for i in range(inputs.shape[0]):\n",
    "        importance[i, :] = np.abs(inputs[i, :] * hidden / total)\n",
    "    return importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for array: array is 1-dimensional, but 2 were indexed",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/lientran/Documents/Machine_Learning _Project/Deep Learning/letter_neuralnetwork.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#W6sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Calculate Garson's algorithm to evaluate feature importance\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#W6sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m importance \u001b[39m=\u001b[39m garson(nn)\n",
      "\u001b[1;32m/Users/lientran/Documents/Machine_Learning _Project/Deep Learning/letter_neuralnetwork.ipynb Cell 7\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#W6sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39m# The subsequent loop goes through each input feature and calculates its importance by multiplying the absolute value of the input's weights by the corresponding hidden weights and dividing by the total importance of the hidden neuron. This is the core of Garson's algorithm, which quantifies the contribution of each input feature to the output.\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#W6sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(inputs\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#W6sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m     importance[i, :] \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mabs(inputs[i, :] \u001b[39m*\u001b[39m hidden \u001b[39m/\u001b[39m total)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#W6sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m \u001b[39mreturn\u001b[39;00m importance\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array: array is 1-dimensional, but 2 were indexed"
     ]
    }
   ],
   "source": [
    "# Calculate Garson's algorithm to evaluate feature importance\n",
    "importance = garson(nn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/Users/lientran/Documents/Machine_Learning _Project/Deep Learning/letter_neuralnetwork.ipynb Cell 8\u001b[0m line \u001b[0;36m1\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#X10sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m targets \u001b[39m=\u001b[39m targets\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#X10sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Train neural network\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#X10sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m error \u001b[39m=\u001b[39m nl\u001b[39m.\u001b[39;49mtrain\u001b[39m.\u001b[39;49mtrain_gd(nn, inputs, targets, epochs\u001b[39m=\u001b[39;49m\u001b[39m500\u001b[39;49m, show\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, goal\u001b[39m=\u001b[39;49m\u001b[39m0.01\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#X10sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m inputs \u001b[39m=\u001b[39m data[[\u001b[39m'\u001b[39m\u001b[39mxbox\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mybox\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mwidth\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mheight\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39monpix\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mxbar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mybar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39mx2bar\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39my2bar\u001b[39m\u001b[39m'\u001b[39m]]\u001b[39m.\u001b[39mvalues\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/lientran/Documents/Machine_Learning%20_Project/Deep%20Learning/letter_neuralnetwork.ipynb#X10sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m targets \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mletter\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39mvalues\u001b[39m.\u001b[39mreshape(\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "File \u001b[0;32m~/Documents/Machine_Learning _Project/.venv/lib/python3.11/site-packages/neurolab/core.py:322\u001b[0m, in \u001b[0;36mTrainer.__call__\u001b[0;34m(self, net, input, target, **kwargs)\u001b[0m\n\u001b[1;32m    320\u001b[0m \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39masfarray(\u001b[39minput\u001b[39m)\n\u001b[1;32m    321\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mndim \u001b[39m==\u001b[39m \u001b[39m2\u001b[39m\n\u001b[0;32m--> 322\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m] \u001b[39m==\u001b[39m net\u001b[39m.\u001b[39mci\n\u001b[1;32m    323\u001b[0m args\u001b[39m.\u001b[39mappend(\u001b[39minput\u001b[39m)\n\u001b[1;32m    324\u001b[0m \u001b[39mif\u001b[39;00m target \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Encode target values as integers\n",
    "le = LabelEncoder()\n",
    "targets = le.fit_transform(data['letter'])\n",
    "\n",
    "# Reshape targets array to match the number of samples\n",
    "targets = targets.reshape(-1, 1)\n",
    "\n",
    "# Train neural network\n",
    "error = nl.train.train_gd(nn, inputs, targets, epochs=500, show=100, goal=0.01)\n",
    "\n",
    "inputs = data[['xbox', 'ybox', 'width', 'height', 'onpix', 'xbar', 'ybar', 'x2bar', 'y2bar']].values\n",
    "targets = data['letter'].values.reshape(-1, 1)\n",
    "\n",
    "# Update input layer to match the number of input features\n",
    "input_size = inputs.shape[1]\n",
    "nn = nl.net.newff([[0, 1] for _ in range(input_size)], [5, 1], [nl.trans.LogSig(), nl.trans.LogSig()])\n",
    "\n",
    "# Train neural network\n",
    "error = nl.train.train_gd(nn, inputs, targets, epochs=500, show=100, goal=0.01)\n",
    "\n",
    "def garson(net):\n",
    "    \"\"\"\n",
    "    Calculate Garson's algorithm to evaluate feature importance.\n",
    "    \"\"\"\n",
    "    inputs = np.hstack(net.layers[0].np['w'])\n",
    "    hidden = np.hstack(net.layers[1].np['w'])\n",
    "    total = np.abs(hidden).sum(axis=0)\n",
    "    importance = np.zeros(inputs.shape)\n",
    "    for i in range(inputs.shape[0]):\n",
    "        importance[i, :] = np.abs(inputs[i, :] * hidden / total)\n",
    "    return importance\n",
    "\n",
    "importance = garson(nn)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
